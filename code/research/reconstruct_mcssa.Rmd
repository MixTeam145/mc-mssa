---
title: "Выделение сигнала на основе критерия Monte Carlo SSA"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10)

library(lattice)
library(parallel)
library(doFuture)
library(doRNG)
library(progressr)
library(tidyr)
library(latex2exp)
library(ggpubr)
library(fpp)

source("../R/mc-mssa.R", chdir = TRUE)
load("./data/reconstruct_mcssa_errors.RData")
load("./data/auto_mcssa_comp.RData")

theme_set(theme_bw())
```

# Алгоритм
Алгоритм восстановления сигнала по наиболее значимой частоте MC-SSA:

1. Найти индекс наиболее значимой частоты (вектора), т.е. $k=\operatorname*{argmax}\limits_i (\widehat p_i - c_i)$, где $c_i$ --- верхняя граница предсказательного интервала, $\omega^\star=\omega_k=k/(2L)$;

2. Если $k-1$ и/или $k+1$-я компоненты тоже значимы, вычислить новое значение $\omega^\star$ как взвешенное среднее частот с весами $w_i=\widehat p_i-c_i$;

3. Провести SSA с некоторой длиной окна (либо SSA с проекцией на косинус с частотой $\omega$) и выбрать первые элементарные компоненты с вкладом периодограммы $>0.5$ на интервале $\omega^\star\pm \delta$, $\delta > 0$.

4. Восстановить выбранные элементарные компоненты.


Алгоритм автоматического выделения сигнала с помощью MC-SSA:

1. Инициализировать массив значимых частот $\Omega^\star\leftarrow\{\}$ и оценку сигнала $\widetilde {\mathsf{S}}\leftarrow 0$, $i\leftarrow1$.

2. Применить MC-SSA с длиной окна $L$, если гипотеза отвергается, STOP.

3. Найти наиболее значимый вектор с частотой $\omega^\star$, $\Omega^\star\leftarrow\Omega^\star\cup\{\omega^\star\}$.

4. По исходному ряду получить новую оценку $\widetilde{\mathsf{S}}$ по частотам $\omega\in\Omega^\star$ (см. предыдущий алгоритм), вычислить остаток.

5. Применить MC-SSA с длиной окна $L$ к остатку.

6. Если гипотеза отвергается или $i > \mathrm{maxiter}$, STOP, иначе $i\leftarrow i+1$ и перейти к пункту $3$.

```{r}
signif_freq <- function(x, n_periodics) {
  significance <- x$statistic$contribution - x$predint$upper
  idx <- which(significance > 0)
  
  if (missing(n_periodics))
    n_periodics <- length(idx)
  
  n_periodics <- min(n_periodics, length(idx))
  
  if (n_periodics == 1) {
    max_idx <- idx[which.max(significance[idx])]
    
    neighbors <- c()
    if ((max_idx - 1) %in% idx)
      neighbors <- c(neighbors, max_idx - 1)
    if ((max_idx + 1) %in% idx)
      neighbors <- c(neighbors, max_idx + 1)
    
    idx <- c(max_idx, neighbors)
    freq <- weighted.mean(x$statistic$freq[idx], significance[idx])
  } else {
    o <- order(-significance[idx])[1:n_periodics]
    idx <- idx[o]
    freq <- x$statistic$freq[idx]
  }
  
  freq
}

reconstruct.mcssa <- function(x,
                              L = (N + 1) %/% 2,
                              delta,
                              groups,
                              method = c("adaptive", "semi-adaptive", "fixed"),
                              n_periodics) {
  method <- match.arg(method)
  
  N <- nrow(x$series)
  eps <- 1e-9
  if (missing(delta))
    delta <- 1 / (4 * x$window) + eps
  freq <- signif_freq(x, n_periodics)
  freq.bins <- lapply(freq, function(f) c(f - delta, f + delta))
  
  params <- list(x = as.vector(x$series), kind = "1d-ssa", L = L, svd.method = "svd") 
  if (method %in% c("semi-adaptive", "fixed")) {
    proj_vectors <- vector("list", length(freq))
    for (i in seq_along(freq)) {
      if (method == "semi-adaptive" || freq[i] == 0.5)
        proj_vectors[[i]] <- cos(2 * pi * (1:L) * freq[i])
      else
        proj_vectors[[i]] <- cbind(
          cos(2 * pi * (1:L) * freq[i]),
          sin(2 * pi * (1:L) * freq[i])
        )
    } 
    params$column.projector <- do.call(cbind, proj_vectors)
  }
  s <- do.call(ssa, params)
  
  if (method %in% c("adaptive", "semi-adaptive")) {
    if (missing(groups))
      groups <- 1:nu(s)
    n_triples <- ifelse(freq == 0.5, 1, 2)
    g <- grouping.auto.pgram(s, groups, "series", freq.bins, 0.5)
    components <- integer()
    for (j in seq_along(freq.bins)) {
      gg <- setdiff(g[[paste0("F", j)]], components)
      len <- min(length(gg), n_triples[j])
      components <- c(components, gg[seq_len(len)])
    }
  } else {
    components <- seq_len(nspecial(s))
  }
  
  r <- reconstruct(s, list(components))
  
  list(signal = r$F1, components = components, freq.bins = freq.bins)
}

auto_mcssa <- function(x,
                       L1,
                       L2 = (N + 1) %/% 2,
                       delta = 1 / (4 * L1) + 1e-9,
                       rank = 20,
                       conf.level = 0.95,
                       trend_freq = 1 / 24,
                       threshold = 0.5,
                       method = c("adaptive", "semi-adaptive", "fixed"),
                       maxit = 10,
                       ...) {
  
  method <- match.arg(method)
  
  N <- length(x)
  
  args <- list(...)
  if (!is.null(args$fixed))
    fixed <- args$fixed
  else
    fixed <- list(phi = NA, d = NA)
  
  params <- list(x = x - mean(x), L = L2, svd.method = "svd")
  if (method == "adaptive") {
    s <- do.call(ssa, params)
  }
  
  m <- mcssa(x, L1, "cos", fixed = fixed, conf.level = conf.level, freq.range = c(trend_freq, 0.5))
  
  freq.exclude <- list(c(0, trend_freq))

  groups <- 1:rank
  freq <- numeric()
  freq.bins <- list()
  n_triples <- integer()
  proj_vectors <- list()
  i <- 1
  while (m$reject && i <= maxit) {
    freq[i] <- signif_freq(m, n_periodics = 1)
    freq.bins[[i]] <- c(freq[i] - delta, freq[i] + delta)
    freq.exclude[[i + 1]] <- freq.bins[[i]]
    if (method %in% c("semi-adaptive", "fixed")) {
      len <- 1:params$L
      if (method == "half" || freq[i] == 0.5)
        proj_vectors[[i]] <- cos(2 * pi * len * freq[i])
      else if (method == "full")
        proj_vectors[[i]] <- cbind(
          cos(2 * pi * len * freq[i]),
          sin(2 * pi * len * freq[i])
        )
      params$column.projector <- do.call(cbind, proj_vectors)
      s <- do.call(ssa, params)
    }
    # browser()
    if (method %in% c("adaptive", "semi-adaptive")) {
      n_triples[i] <- ifelse(freq[i] == 0.5, 1, 2)
      g <- grouping.auto.pgram(s, groups, "series", freq.bins, threshold)
      components <- integer()
      for (j in seq_along(freq.bins)) {
        gg <- setdiff(g[[paste0("F", j)]], components)
        len <- min(length(gg), n_triples[j])
        components <- c(components, gg[seq_len(len)])
      }
    } else {
      components <- seq_len(nspecial(s))
    }
    
    r <- reconstruct(s, list(components))
    x_resid <- resid(r)
    
    # model <- as.list(arfima_whittle(x_resid, c(fixed$phi, fixed$d), freq.exclude))
    # model$N <- N
    m <- mcssa(x_resid, L1, "cos", fixed = fixed, conf.level = conf.level, freq.range = c(trend_freq, 0.5))
    
    i <- i + 1
  }
  
  if (i > 1)
    out <- list(signal = r$F1, components = components, freq.bins = freq.bins)
  else
    out <- list(signal = rep(0, N), components = integer(), freq.bins = numeric())
 
  out
}
```

```{r, include=FALSE}
angle.fun <- function(P, Q) {
  angle <- function(P1, P2, Q1, Q2) {
    t <- acos((P1 * P2 + Q1 * Q2) / sqrt(
      P1 ^ 2 + Q1 ^ 2) / sqrt(P2 ^ 2 + Q2 ^ 2))
    t[!is.nan(t)]
  }
  angles <- angle(P1 = P[-length(P)],
                  P2 = P[-1],
                  Q1 = Q[-length(Q)],
                  Q2 = Q[-1])
  
  vv <- var(angles)
  mm <- mean(angles)
  tau_value <- vv / min(1, mm ^ 2)
  return(list(tau_value = tau_value,
              mean_angle = mm))
}

periodic_grouping_angle_reg <- function(ssa_obj,
                                        groups,
                                        threshold = 0.01,
                                        eps = 1e-9,
                                        s_0 = 1,
                                        rho_0 = 0.9,
                                        p_0 = 0.05,
                                        ...) {
  groups <- sort(unique(unlist(groups)))

  if (missing(groups)) {
    groups <- 1:nu(ssa_obj)
  }

  # Identification of periodics with frequency 0.5
  L <- ssa_obj$window
  Fs <- ssa_obj$U[, groups, drop = FALSE]
  if (length(groups) == 1){
    Fs <- matrix(Fs, ncol = 1)
    sums <- sum(abs(sign(Fs[1:(L - 1),]) + sign(Fs[2:L,])) / 2)
  } else {
    sums <- colSums(abs(sign(Fs[1:(L - 1),]) + sign(Fs[2:L,])) / 2)
  }
  one_el_gamma <- sums / (L - 1)
  one_el_gamma <- one_el_gamma[one_el_gamma < p_0]
  I_2_final <- groups[sums / (L - 1) < p_0]

  groups <- setdiff(groups, I_2_final)

  if (length(groups) >= 2){
    filter_mask <- rep(FALSE, length(groups) - 1)
    tau <- numeric(length(groups) - 1)
    I_1_freqs <- numeric(length(groups) - 1)
    for (j in seq_along(groups)[-length(groups)]) {
      res <- angle.fun(P = ssa_obj$U[, groups[j]],
                       Q = ssa_obj$U[, groups[j + 1]])
      tau[j] <- res$tau_value
      I_1_freqs[j] <- res$mean_angle / (2 * pi)
    }

    o <- order(tau)
    mask <- rep(TRUE, length(groups) - 1)
    for (i in o) {
      if (mask[i]) {
        if (i > 1)
          mask[i - 1] <- FALSE
        if (i < length(mask))
          mask[i + 1] <- FALSE
      }
    }

    mask <- mask & tau - threshold < eps
    tau_raw <- tau
    two_el_tau <- tau[mask]
    I_1_final <- groups[c(mask, FALSE)]
    I_1_final <- sort(c(I_1_final, I_1_final + 1))
    I_1_freqs <- I_1_freqs[mask]

    # sorted_indices <- order(tau)
    # for (j in seq_along(sorted_indices)) {
    #   left_taken <- FALSE
    #   if (sorted_indices[j] > 1){
    #     if ((groups[sorted_indices[j]] == groups[sorted_indices[j] - 1]) &
    #         (filter_mask[sorted_indices[j] - 1] == TRUE))
    #       left_taken <- TRUE
    #   }
    #
    #   right_taken <- FALSE
    #   if (sorted_indices[j] < length(sorted_indices)){
    #     if ((groups[sorted_indices[j]] == groups[sorted_indices[j] + 1]) &
    #         (filter_mask[sorted_indices[j] + 1] == TRUE))
    #       right_taken <- TRUE
    #   }
    #
    #   if (!left_taken & !right_taken & (tau[sorted_indices[j]] - threshold < eps))
    #     filter_mask[sorted_indices[j]] <- TRUE
    # }

    # tau_raw <- tau
    # two_el_tau <- tau[c(filter_mask, FALSE)]
    # I_1_final <- groups[c(filter_mask, FALSE)]
    # I_1_final <- sort(c(I_1_final, I_1_final + 1))
    # I_1_freqs <- I_1_freqs[filter_mask]
  } else{
    I_1_final <- numeric(0)
    I_1_freqs <- numeric(0)
    two_el_tau <- numeric(0)
    tau_raw <- numeric(0)
  }

  list(I_1 = I_1_final,
       two_el_tau = two_el_tau,
       I_1_freqs = I_1_freqs,
       I_2 = I_2_final,
       tau_raw = tau_raw,
       one_el_gamma = one_el_gamma)
}

```


# Пример
Пусть $\phi=0.7$, $\sigma^2=1$, $N=200$.
```{r}
phi <- 0.7
sigma2 <- 1
N <- 200
model <- list(phi = phi, sigma2 = sigma2, N = N)
```

```{r}
em_harmonic <- function(N, freq, A = 1, a = 0) {
  A * exp(a * (1:N)) * cos(2 * pi * (1:N) * freq)
}
```

Сигнал:
$$
s_n = 0.075 \exp(0.02n)\cos(2 \pi n / 8) + 2\cos(2 \pi n / 4) + 0.2\cdot (-1)^n.
$$
```{r}
omega <- 0.125
signal <- mapply(em_harmonic, N, c(1, 2, 4) * omega, c(0.075, 1, 0.2), c(0.02, 0, 0)) |> rowSums()

set.seed(1234)
f <- generate_channel(model, signal)

# pdf("../../tex/science2025/img/noise_ts.pdf", width = 8, height = 4)
xyplot.ts(f)
# dev.off()

# pdf("../../tex/science2025/img/noise_ts_signal.pdf", width = 8, height = 4)
xyplot.ts(
  cbind(Original = f, Signal = signal),
  superpose = TRUE,
  col = c("grey", "red"),
  lwd = 2,
  auto.key = list(space = "top")
)
# dev.off()

s <- ssa(f - mean(f), svd.method = "svd")
# pdf("../../tex/science2025/img/reconstructed_ts.pdf", width = 8, height = 4)
plot(s, "series", groups = 1:15)
# dev.off()
```

Пусть $L=20$.
```{r}
L <- 50
set.seed(1)
m1 <- mcssa(f, L, "cos", model = model, conf.level = 0.95)
set.seed(1)
m2 <- mcssa(f, L, "cos", fixed = list(phi = NA, d = 0), conf.level = 0.95)
```

Реальная модель, значимы все три частоты, соответствующие сигналу:
```{r}
p1 <- plot(m1, text.size = 8, point.size = 0.5) 
# ggsave("../../tex/science2025/img/mcssa_real.pdf", p1, device = "pdf", width = 10, height = 10, units = "cm") 
```

Оцененная модель, значима только одна частота:
```{r}
p2 <- plot(m2, text.size = 8, point.size = 0.5)
# ggsave("../../tex/science2025/img/mcssa_estimated.pdf", p2, device = "pdf", width = 10, height = 10, units = "cm")
```

Последовательно применяя MC-SSA, весь сигнал выделяется:
```{r}
# set.seed(10)
r <- auto_mcssa(f, L, trend_freq = 0, fixed = list(phi = NA, d = 0), delta = 1 / 80)

# pdf("../../tex/science2025/img/auto_mcssa_result.pdf", width = 8, height = 4)
xyplot.ts(
  cbind(
    Signal = signal,
    Estimated = r$signal
  ),
)
# dev.off()

cat(
  "Selected components:", r$components
)
```

# Сравнение вариантов с проекцией и без
```{r}
mcssa_errors <- function(L, model, signal, M = 500, n_periodics = 1, ...) {
  pb <- progressor(M)
  result <- foreach (i = 1:M, .options.RNG = 1) %dorng% {
    pb()
    f <- generate_channel(model, signal)
    m <- mcssa(f, L, "cos", model = model, conf.level = 0.95)
    if (m$reject) {
      r.adaptive <- reconstruct.mcssa(m, n_periodics = n_periodics, ...)
      r.semi <- reconstruct.mcssa(m, method = "semi-adaptive", n_periodics = n_periodics, ...)
      r.fixed <- reconstruct.mcssa(m, method = "fixed", n_periodics = n_periodics, ...)
      mse.adaptive <- mean((r.adaptive$signal - signal)^2)
      mse.semi <- mean((r.semi$signal - signal)^2)
      mse.fixed <- mean((r.fixed$signal - signal)^2)
    }
    else {
      mse.adaptive <- mse.semi <- mse.fixed <- NA
    }
    c(mse.adaptive, mse.semi, mse.fixed)
  }
  result <- do.call(rbind, result) |> data.frame()
  colnames(result) <- c("adaptive", "semi-adaptive", "fixed")
  result
}
```

```{r eval=FALSE, include=FALSE}
cores <- 15

# Setting up parallel computing
plan(multisession, workers = min(cores, detectCores() - 1))
registerDoFuture()
```

Пусть $N=99$, $L=40$, $\phi=0.7$, $\delta=0.025$. Рассмотрим разную зашумленность ряда: $\sigma^2\in\{0.2, 0.4, 0.6, 0.8, 1\}$.
```{r}
N <- 99
L <- 40
omega <- 0.115
phi <- 0.7
sigma2s <- c(0.2, 0.4, 0.6, 0.8, 1)
models <- lapply(sigma2s, function(sigma2) list(phi = 0.7, sigma2 = sigma2, N = N))
```
Рассмотрим два типа сигнала:

1. $$s_n=A\cos(2\pi \omega n),$$ где $A=1$.

2. $$s_n=Ae^{\alpha n}\cos(2\pi \omega n),$$ где $A=0.025$, $\alpha=0.05$.

Возьмем $\omega=0.115$.
```{r}
signal1 <- cos(2 * pi * (1:N) * omega)
signal2 <- 0.025 * exp(0.05 * (1:N)) * cos(2 * pi * (1:N) * omega)
```

```{r eval=FALSE, include=FALSE}
mse1 <- lapply(models, function(model) mcssa_errors(L, model, signal1, delta = 0.025))
mse1 <- 
  lapply(mse1, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r eval=FALSE, include=FALSE}
mse2 <- lapply(models, function(model) mcssa_errors(L, model, signal4, delta = 0.025))
mse2 <- 
  lapply(mse2, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r eval=FALSE, include=FALSE}
mse1_delta_smaller <- lapply(models, function(model) mcssa_errors(L, model, signal1, delta = 0.0125))
mse1_delta_smaller <- 
  lapply(mse1_delta_smaller, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  tidyr::pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r eval=FALSE, include=FALSE}
mse2_delta_smaller <- lapply(models, function(model) mcssa_errors(L, model, signal2, delta = 0.0125))
mse2_delta_smaller <- 
  lapply(mse2_delta_smaller, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r eval=FALSE, include=FALSE}
mse1_delta_bigger <- lapply(models, function(model) mcssa_errors(L, model, signal2, delta = 0.05))
mse1_delta_bigger <- 
  lapply(mse1_delta_bigger, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r eval=FALSE, include=FALSE}
mse2_delta_bigger <- lapply(models, function(model) mcssa_errors(L, model, signal4, delta = 0.05))
mse2_delta_bigger <- 
  lapply(mse2_delta_bigger, function(mse) colMeans(mse, na.rm = TRUE)) |>
  bind_rows() |>
  mutate(sigma2 = sigma2s) |>
  pivot_longer(1:3, names_to = "method", values_to = "MSE") |>
  mutate(method = factor(method, levels = unique(method)))
```

```{r include=FALSE}
ylim_p1 <- ylim(
  min(mse1$MSE, mse1_delta_smaller$MSE, mse1_delta_bigger$MSE),
  max(mse1$MSE, mse1_delta_smaller$MSE, mse1_delta_bigger$MSE)
)

ylim_p2 <- ylim(
  min(mse2$MSE, mse2_delta_smaller$MSE, mse2_delta_bigger$MSE),
  max(mse2$MSE, mse2_delta_smaller$MSE, mse2_delta_bigger$MSE)
)

plot_mse <- function(data, plot.right = FALSE) {
  p <- ggplot(data, aes(x = sigma2, y = MSE, colour = method)) +
    geom_point() +
    geom_line() +
    theme(legend.title = element_blank()) +
    xlab(TeX("$\\sigma^2$"))
  if (plot.right)
    p <- p + ggtitle(TeX(r"(\alpha\ne{0})")) + ylim_p2
  else
    p <- p + ggtitle(TeX(r"(\alpha=0)")) + ylim_p1
  p
}
```

```{r}
p1 <- plot_mse(mse1)
p2 <- plot_mse(mse2, TRUE)
(p <- ggarrange(p1, p2, ncol = 2, common.legend = TRUE, legend = "bottom"))
# ggsave("../../tex/science2025/paper/img/mse.pdf", p, device = "pdf", width = 10, height = 4)
```

Теперь пусть $\delta=0.0125$.
```{r}
p1 <- plot_mse(mse1_delta_smaller)
p2 <- plot_mse(mse2_delta_smaller, TRUE)
(p <- ggarrange(p1, p2, ncol = 2, common.legend = TRUE, legend = "bottom"))
# ggsave("../../tex/science2025/paper/img/mse_delta_smaller.pdf", p, device = "pdf", width = 10, height = 4)
```

Теперь пусть $\delta=0.05$.
```{r}
p1 <- plot_mse(mse1_delta_bigger)
p2 <- plot_mse(mse2_delta_bigger, TRUE)
(p <- ggarrange(p1, p2, ncol = 2, common.legend = TRUE, legend = "bottom"))
# ggsave("../../tex/science2025/paper/img/mse_delta_bigger.pdf", p, device = "pdf", width = 10, height = 4)
```


# Сравнение подходов к выделению сигнала
```{r}
auto_mcssa_comp <- function(L, model, signal, noise_type, conf.level = 0.95, M = 500) {
  temp_env <- new.env()
  suppressMessages(source("./auto_ssa/scripts.R", local = temp_env, chdir = TRUE))
  assign("sign_level", 1 - conf.level, envir = temp_env)
  assign("noise_type", noise_type, envir = temp_env)
  
  fixed <- list(phi = NA, d = 0)
  if (noise_type == "white")
      fixed$phi <- 0
  
  pb <- progressor(M)
  result <- foreach (i = 1:M, .options.RNG = 1) %dorng% {
    pb()
    
    f <- generate_channel(model, signal)
    r <- auto_mcssa(f, L, conf.level = conf.level, trend_freq = 0, fixed = fixed)
    mse1 <- mean((signal - r$signal)^2)
    
    assign("f", f, envir = temp_env)
    
    local(
      dec <- auto_ssa(
        f,
        L = (length(f) + 1) %/% 2,
        20,
        sign_level = sign_level,
        auto_trend_freq = 0,
        noise_type = noise_type,
        eossa_delta = 1e-4
      ),
      temp_env
    )
    
    mse2 <- mean((get("dec", envir = temp_env)$periodics - signal)^2)
    c(mse1, mse2)
  
  }
  result <- do.call(rbind, result) |> data.frame()
  colnames(result) <- c("mse_auto_mcssa", "mse_auto_ssa")
  result
}
```

```{r eval=FALSE, include=FALSE}
cores <- 15

# Setting up parallel computing
plan(multisession, workers = min(cores, detectCores() - 1))
registerDoFuture()
```

```{r eval=FALSE, include=FALSE}
# Run this in R console to enable progress bar
handlers(global = TRUE)
```

Пусть $N=100$, $L=20$, $\phi=0.5$, $\sigma^2=1$.
```{r}
N <- 100
L <- 20
phi <- 0.5
sigma2 <- 1
model_wn <- list(sigma2 = sigma2, N = N)
model_rn <- list(phi = phi, sigma2 = sigma2, N = N)
```

Возьмем следующий сигнал:
$$
s_n=0.2\exp(0.05 n)\cos(2\pi n/4) + 2\cos(2\pi n / 3) + (-1)^n.
$$
```{r}
signal <- mapply(em_harmonic, N, c(1 / 4, 1 / 3, 1 / 2), c(0.2, 2, 1), c(0.05, 0, 0)) |> rowSums()

set.seed(1234)
f <- generate_channel(model_wn, signal)

xyplot.ts(
  cbind(f, signal),
  superpose = TRUE,
  col = c("grey", "red"),
  lwd = 2,
  auto.key = list(
    text = c("Original", "Signal"),
    space = "top"
  )
)
```

```{r eval=FALSE}
mse_wn <- auto_mcssa_comp(L, model_wn, signal, noise_type = "white", M = 100)
mse_rn <- auto_mcssa_comp(L, model_rn, signal, noise_type = "red", M = 100)
```

Модель белого шума:
```{r}
data.frame(Mean = colMeans(mse_wn), Median = colMedians(as.matrix(mse_wn)))
```

Модель красного шума:
```{r}
data.frame(Mean = colMeans(mse_rn), Median = colMedians(as.matrix(mse_rn)))
```


# Реальный пример
```{r}
data("elecequip")
xyplot(elecequip)
```

Тренд выделим собственными силами:
```{r}
s_elec <- ssa(elecequip, 36, svd.method = "svd")
plot(s_elec, "vectors")
```

```{r}
r_elec <- reconstruct(s_elec, list(Trend = c(1:2, 5)))
auto_elec <- auto_mcssa(resid(r_elec), L1 = 36, L2 = 84, fixed = list(phi = NA, d = 0))
```

```{r}
elec_residuals <-  resid(r_elec) - auto_elec$signal
xyplot.ts(
  cbind(Original = elecequip, Trend = r_elec[[1]], Signal = auto_elec$signal, Residuals = elec_residuals),
  superpose = TRUE,
  col = c("grey", "red", "blue", "darkgreen"),
  lwd = 2,
  auto.key = list(space = "right")
)
```

```{r}
auto_elec$components
s_elec <- ssa(resid(r_elec), 84, svd.method = "svd")
plot(s_elec, "vectors", idx = 1:20)
```

