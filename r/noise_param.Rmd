---
title: "Оценка параметров красного шума"
output:
  html_document:
    df_print: paged
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("mcmssa_utils.R")
source("noise_estim.R")
library(foreach)
library(doSNOW)
library(parallel)
```

Пусть нам известно, что данный временной ряд представляет собой реализацию красного шума, но параметры $\varphi$ и $\delta$ неизвестны, т.е.
\[
f_n = \varphi f_{n-1} + \delta\varepsilon_n,\quad n=1,\ldots,N,
\]
где $\varepsilon_n\sim N(0, 1)\; \forall n$.
```{r, results='hide'}
varphi <- 0.7
delta <- 1
N <- 100
model <- list(varphi = varphi, delta = delta, N = N)
M <- 100
G <- 100
cores <- detectCores()
pb <- txtProgressBar(max = M, style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
```
Существует множество варивнтов оценки параметров, остановимся на 2-х вариантах. Один из них базируется на методе arima, другой описан в работе AllenSmith1996. Далее будем оценивать только $\varphi$.
```{r}
est.arima.varphi <- numeric()
est.as.varphi <- numeric()
set.seed(5)
for (i in 1:M) {
  f <- one.channel.ts(model = model, 0)
  est.arima.varphi <- append(est.arima.varphi, est.model.arima(f)$varphi)
  est.as.varphi <- append(est.as.varphi, est.model.as(f)$varphi)
}
```
По значению MSE оба метода показывают примерно равную точность, далее для определенности будем использовать первый.
```{r}
mean((est.arima.varphi - varphi)^2)
mean((est.as.varphi - varphi)^2)
```
Пусть теперь временной ряд представляет собой смесь сумму косинуса с периодом $\omega=0.075$ и амплитудой $A=3$ и красного шума. 
```{r}
omega <- 0.075
signal <- signal.one.channel(model$N, omega, A = 3)
```
Оценим параметры в этом случая в два этапа: сначала оценим параметры исходног ряда, затем, если MC-SSA обнаружит сигнал, восстановим его и оценим параметры "остатка". Интуитивно кажется, что оценка должна стать точнее. Будем использовать собственные векторы в качестве векторов для проекции с целью облегчения дальнейшего выделения периодичной компоненты, если алгоритм отвергнет нулевую гипотезу.
```{r, results='hide'}
res <- numeric()
set.seed(5)
for(i in 1:M) {
  f <- one.channel.ts(model = model, signal = signal)
  varphi.before <- est.model.arima(f)$varphi
  m <- MonteCarloSSA(f, L = 50, D = 1, basis = "ev", kind = "ev", G = G, level.conf = 0.975)
  varphi.after <- varphi.before
  if (m$reject) {
    suspect <- which(m$v > m$upper)
    s <- ssa(f, L = 50, D = 1, kind = "toeplitz-ssa")
    r <- reconstruct(s, groups = list(signal = suspect))
    varphi.after <- est.model.arima(residuals(r))$varphi
  }
  res <- cbind(res, rbind(varphi.before,varphi.after))
}
```
Как видно из значений MSE, выделение сигнала, действительно положительно повлияло на точность оценненного параметра.
```{r}
rowMeans((res - varphi)^2)
```
Поскольку $\mathsf{MSE}(\hat\varphi)=\mathsf D(\hat\varphi) + (\mathsf E\hat\varphi -\varphi)^2$, интересно посмотреть отдельно на дисперсию и на отклонение оценки от настоящего значения.
Дисперсия:
```{r}
rowVars(res)
```
Отклонение:
```{r}
rowMeans(res) - varphi
```
Проверим гипотезу, что смещение после выделения равно нулю.
\[
H_0:~ \mathsf E\hat\varphi=\varphi\\
H_1:~\mathsf E\hat\varphi\ne\varphi\\
t=\frac{\sqrt{n-1}(\overline{\hat\varphi}-\varphi)}{s}\to N(0, 1)
\]
```{r}
alpha <- 0.025
t <- sqrt(M - 1) * (mean(res[2,]) - varphi) / sqrt(var(res[2,]))
t.critical <- qnorm(1-alpha/2)
if (t > t.critical | t < -t.critical)
  print("rejected")
```
Дисперсия выросла, в то время как отклонение уменьшилось в абсолютном значении и поменяло знак, что говорит о том, что в среднем, после выделения "сигнала", оценка параметра авторегрессии находится слева от настоящего значения. Проверим это утверждение для остальных частот. Будем брать частоты от $0.05$ до $0.5$ с шагом $0.05$. 
```{r, results='hide'}
omega <- seq(0.05, 0.5, 0.05)
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
res1 <- list()
for (j in 1:length(omega))
{
  set.seed(5)
  signal <- signal.one.channel(model$N, omega[j], A = 3)
  res1[[j]] <- foreach (i=1:M, .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
             .combine='cbind', .options.snow = opts) %dopar%
    {
      f <- one.channel.ts(model = model, signal = signal)
      varphi.before <- est.model.arima(f)$varphi
      m <- MonteCarloSSA(f, L = 50, D = 1, basis = "ev", kind = "ev", G = G, level.conf = 0.975)
      varphi.after <- varphi.before
      if (m$reject) {
        suspect <- which(m$v > m$upper)
        s <- ssa(f, L = 50, D = 1, kind = "toeplitz-ssa")
        r <- reconstruct(s, groups = list(signal = suspect))
        varphi.after <- est.model.arima(residuals(r))$varphi
      }
      rbind(varphi.before,varphi.after)
    }
}
stopCluster(cluster)
```

```{r}
mse.before1 <- sapply(res1, function(r) mean((r[1,]-varphi)^2))
mse.after1 <- sapply(res1, function(r) mean((r[2,] - varphi)^2))
plot(omega, mse.before1, type = "b")
lines(omega, mse.after1, type = "b", col = "red")
```

```{r}
var.before1 <- sapply(res1, function(r) var(r[1,]))
var.after1 <- sapply(res1, function(r) var(r[2,]))
plot(omega, var.before1, type = "b")
lines(omega, var.after1, type = "b", col = "red")
```

```{r}
bias.before1 <- sapply(res1, function(r) mean(r[1,]) - varphi)
bias.after1 <- sapply(res1, function(r) mean(r[2,]) - varphi)
plot(omega, bias.before1, type = "b")
lines(omega, bias.after1, type = "b", col = "red")
```

По графику 3 видно, что основной вклад в ошибку вносит смещение, процедура это смещение сильно уменьшает, делая слабо-отрицательной.

Заметим, что чем меньше амплитуда у гармоники, тем меньше должно быть улучшение. Проверим это для $A=0.5$.
```{r, results='hide'}
omega <- 0.075
signal <- signal.one.channel(model$N, omega, A = 0.5)
res2 <- numeric()
set.seed(5)
for(i in 1:M) {
  f <- one.channel.ts(model = model, signal = signal)
  varphi.before <- est.model.arima(f)$varphi
  m <- MonteCarloSSA(f, L = 50, D = 1, basis = "ev", kind = "ev", G = G, level.conf = 0.975)
  varphi.after <- varphi.before
  if (m$reject) {
    suspect <- which(m$v > m$upper)
    s <- ssa(f, L = 50, D = 1, kind = "toeplitz-ssa")
    r <- reconstruct(s, groups = list(signal = suspect))
    varphi.after <- est.model.arima(residuals(r))$varphi
  }
  res2 <- cbind(res2, rbind(varphi.before,varphi.after))
}
```

```{r}
rowMeans((res2 - varphi)^2)
rowVars(res2)
rowMeans(res2) - varphi
```
Действительно, улучшение практически незначительное.

Посмотрим, как будет вести себя процедура, если сигнала на самом деле не будет.
```{r, results='hide'}
signal <- 0
res3 <- numeric()
set.seed(5)
for(i in 1:M) {
  f <- one.channel.ts(model = model, signal = signal)
  varphi.before <- est.model.arima(f)$varphi
  m <- MonteCarloSSA(f, L = 50, D = 1, basis = "ev", kind = "ev", G = G, level.conf = 0.975)
  varphi.after <- varphi.before
  if (m$reject) {
    suspect <- which(m$v > m$upper)
    s <- ssa(f, L = 50, D = 1, kind = "toeplitz-ssa")
    r <- reconstruct(s, groups = list(signal = suspect))
    varphi.after <- est.model.arima(residuals(r))$varphi
  }
  res3 <- cbind(res3, rbind(varphi.before,varphi.after))
}
```

```{r}
rowMeans((res3 - varphi)^2)
rowVars(res3)
rowMeans(res3) - varphi
```

Таким образом, оценка улучшилась настолько незначительно, можно считать, что данная процедура не влияет плохо на результат, если ряд представляет из себя чистый красный шум.


