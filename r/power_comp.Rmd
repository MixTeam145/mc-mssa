---
title: "Сравнение мощностей"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("mcmssa_utils.R")
source("noise_estim.R")
library(foreach)
library(doSNOW)
library(parallel)
library(doRNG)
```

Сравним графики ошибок первого рода и мощностей метода MC-SSA, используя, истинные параметры красного шума, оцененные методом arima и оцененные методом extract (т.е. с предварительным извлечением сигнала, если такой обнаружится). Для оценки мощности использовался синус с амплитудой $A=1.5$.
```{r, results='hide'}
N <- 100
varphi <- 0.7
delta <- 1
omega <- 0.075
Ls <- c(10, 20, 50, 80, 90)
L_idx <- 1:length(Ls)
D <- 1 
G <- 1000
M <- 1000
model <- list(varphi = varphi,
              delta = delta,
              N = N)
pb <- txtProgressBar(max = M, style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
signal <- signal.one.channel(N, omega, 1.5)
```

```{r, results='hide'}
p.values_h0_arima <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M, 
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, 0)
      r <- MonteCarloSSA(f = f,
                         model = est.model.arima(f),
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h0_arima[[k]] <- pvals
}
stopCluster(cluster)
```

```{r results='hide'}
p.values_h0 <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M,
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, 0)
      r <- MonteCarloSSA(f = f,
                         model = model,
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h0[[k]] <- pvals
}
stopCluster(cluster)
```

```{r}
# Поправка при L=50
load("p_values_for_extract.RData")
alphas <- c(seq(0, 0.025, 0.0001), seq(0.025, 1, 0.001))
alphas_idx <- seq_along(alphas)
alphas_corrected_arima <- correction(p.values_h0_arima[[3]])
```

```{r, results='hide'}
p.values_h0_extract <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M,
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, 0)
      r <- MonteCarloSSA(f = f,
                         model = est.model.extract(f, alpha = 0.1),
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h0_extract[[k]] <- pvals
}
stopCluster(cluster)
```

```{r, results='hide'}
p.values_h1 <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M,
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, signal)
      r <- MonteCarloSSA(f = f,
                         model = model,
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h1[[k]] <- pvals
}
stopCluster(cluster)
```

```{r, results='hide'}
p.values_h1_arima <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M,
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, signal)
      r <- MonteCarloSSA(f = f,
                         model = est.model.arima(f),
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h1_arima[[k]] <- pvals
}
stopCluster(cluster)
```

```{r, results='hide'}
p.values_h1_extract <- list()
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)
for (k in 1:5) {
  pvals <- foreach (i=1:M,
                    .export=c('ssa', 'nu', 'parestimate', 'Norm', 'rowQuantiles', 'reconstruct'),
                    .combine='cbind',
                    .options.snow=opts) %dopar%
    {
      f <- one.channel.ts(model, signal)
      r <- MonteCarloSSA(f = f,
                         model = est.model.extract(f, alpha = 0.1),
                         L = Ls[k],
                         D = 1,
                         basis = "ev",
                         kind = "ev",
                         G = G,
                         level.conf = NULL)
      r$p.value
    }
  p.values_h1_extract[[k]] <- pvals
}
stopCluster(cluster)
```

```{r}
clrs <- c("black", "red", "blue")
legends <- c("True model", "Estimated model (arima)", "Estimated model (extract)")
lwds <- c(2,2,2)
```

```{r}
#alphaI <- lapply(p.values_h0, function(p) sapply(alphas, function(a) sum(p < a) / M))
alphaI_arima <- lapply(p.values_h0_arima, function(p) sapply(alphas, function(a)  sum(p < a) / M))
alphaI_extract <- lapply(p.values_h0_extract, function(p) sapply(alphas, function(a)  sum(p < a) / M))

#beta <- lapply(p.values_h1, function(p) sapply(alphas, function(a) sum(p < a) / M))
beta_arima <- lapply(p.values_h1_arima, function(p) sapply(alphas, function(a) sum(p < a) / M))
beta_extract <- lapply(p.values_h1_extract, function(p) sapply(alphas, function(a) sum(p < a) / M))
```
Посмотрим на графики ошибок первого рода. Видим, что при $L=10,20$ критерии с оцененными параметрами до определенного момента консервативны, потом радикальные. Для остальных $L$ критерии радикальные. Заметим, что для всех $L$ графики критериев с оцененными параметрами практически идентичны, что соответствует $\pm$ одинаковой точности оценок при отсутствии сигнала. 
```{r}
pdf("type1error_arima.pdf", width = 15, height = 5, bg = "white")
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, xlab = 'significance level', ylab = 'type I error', cex.lab=1.8, cex.axis=1.8, cex.sub=1.8)
for (i in 1:5)
  lines(alphas, alphaI_arima[[i]], col = clrs[i], lwd = lwds[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds, cex = 2)
dev.off()
```

```{r}
pdf("type1error_extract.pdf", width = 15, height = 5, bg = "white")
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, xlab = 'significance level', ylab = 'type I error', cex.lab=1.8, cex.axis=1.8, cex.sub=1.8)
for (i in 1:5)
  lines(alphas, alphaI_extract[[i]], col = clrs[i], lwd = lwds[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds, cex = 2)
dev.off()
```

Если посмотреть на ROC-кривые критериев, видим серьезное повышение мощности, используя метод extract, при $L=10,20,50$. Для остальных $L$ улучшения нет.
```{r}
pdf("roc_arima.pdf", width = 15, height = 5, bg = "white")
plot(c(0,1),c(0,1), type="l", col="blue", lty = 2, xlab = 'type I error', ylab = 'power', cex.lab=1.8, cex.axis=1.8, cex.sub=1.8)
for (i in 1:5)
  lines(alphaI_arima[[i]], beta_arima[[i]], col = clrs[i], lwd = lwds[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds, cex = 2)
dev.off()
```

```{r}
pdf("roc_extract.pdf", width = 15, height = 5, bg = "white")
plot(c(0,1),c(0,1), type="l", col="blue", lty = 2, xlab = 'type I error', ylab = 'power', cex.lab=1.8, cex.axis=1.8, cex.sub=1.8)
for (i in 1:5)
  lines(alphaI_extract[[i]], beta_extract[[i]], col = clrs[i], lwd = lwds[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds, cex = 2)
dev.off()
```
