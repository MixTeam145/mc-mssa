---
title: "Разные параметры сигнала/шума"
output: html_notebook
---

# Зависимость от параметров шума ($\varphi$).

```{r, include=FALSE}
source("mcmssa_utils.R")
library(foreach)
library(doParallel)
library(doRNG)
library(doSNOW)
library(gcplyr)
```

```{r}
N <- 100
D <- 1
delta <- 1
omega <- 0.075
G <- 1000
M <- 1000
Ls <- c(10, 20, 50, 80, 90)
```

```{r, include=FALSE}
pb <- txtProgressBar(max = M, style = 3)
progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)
```

```{r}
alphas <- 0:1000/1000
clrs <- c('black', 'red', 'green', 'orange', 'purple')
lwds <- c(2, 1, 1, 1, 1)
```

1. $\varphi=0.7$. 
```{r}
varphi <- 0.7
A <- 1
model <- list(varphi = varphi,
              delta = delta,
              N = N)
signal <- signal.one.channel(model$N, omega, A)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_noise_phi.7 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, 0)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_noise_phi.7[[idx]] <- result
}

stopCluster(cluster)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_signal_phi.7 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, signal)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_signal_phi.7[[idx]] <- result
}

stopCluster(cluster)
```

```{r}
alphaI_phi.7 <- lapply(p.values_noise_phi.7, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
beta_phi.7 <- lapply(p.values_signal_phi.7, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, xlab = 'significance level', ylab = 'type I error')
for (i in seq_along(Ls))
  lines(alphas, alphaI_phi.7[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, xlab = 'type I error', ylab = 'power')
for (i in seq_along(Ls))
  lines(alphaI_phi.7[[i]], beta_phi.7[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Видно, что оптимальная длина окна $L=90$.

2. $\varphi=0.9$
```{r}
varphi <- 0.9
model$varphi <- varphi
A <- 1.2
signal <- signal.one.channel(model$N, omega, A)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_noise_phi.9 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, 0)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_noise_phi.9[[idx]] <- result
}

stopCluster(cluster)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_signal_phi.9 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, signal)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_signal_phi.9[[idx]] <- result
}

stopCluster(cluster)
```

```{r}
alphaI_phi.9 <- lapply(p.values_noise_phi.9, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
beta_phi.9 <- lapply(p.values_signal_phi.9, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "Type I error", xlab = 'significance level', ylab = 'type I error')
for (i in seq_along(Ls))
  lines(alphas, alphaI_phi.9[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Самым радикальным является критерий с $L=80$, при $\varphi=0.7$ $L=90$ и $L=80$ были примерно одинаковыми по радикальности.
```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "ROC curve", xlab = 'type I error', ylab = 'power')
for (i in seq_along(Ls))
  lines(alphaI_phi.9[[i]], beta_phi.9[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Тут также оптимальная длина окна $L=90$

3. $\varphi=0.1$
```{r}
varphi <- 0.1
model$varphi <- varphi
A <- 0.6
signal <- signal.one.channel(model$N, omega, A)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1)

p.values_noise_phi.1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts,
    .options.RNG=1
  ) %dopar% {
    f <- one.channel.ts(model, 0)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_noise_phi.1[[idx]] <- result
}

stopCluster(cluster)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1)

p.values_signal_phi.1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts,
    .options.RNG=1
  ) %dopar% {
    f <- one.channel.ts(model, signal)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_signal_phi.1[[idx]] <- result
}

stopCluster(cluster)
```

```{r}
alphaI_phi.1 <- lapply(p.values_noise_phi.1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
beta_phi.1 <- lapply(p.values_signal_phi.1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "Type I error", xlab = 'significance level', ylab = 'type I error')
for (i in seq_along(Ls))
  lines(alphas, alphaI_phi.1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Тут видим очень сильную радикальность при $L=80$ и $L=90$, причем $L=90$ уже радикальнее. 
```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "ROC curve", xlab = 'type I error', ylab = 'power')
for (i in seq_along(Ls))
  lines(alphaI_phi.1[[i]], beta_phi.1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Теперь оптимальной длиной окна является $L=10$ и $L=20$, но отметим, что для $L=80$ и $L=90$ удалось построить не всю ROC-кривую из-за сильной радикальности критериев.

Удивляет, что при $\varphi=0.9$ метод с $L=90$ становится менее радикальным, чем $L=80$. Посмотрим, исчезает ли это различие с увеличением $N$. Длины окна просто увеличим в 2 раза. Тогда нас интересуют $L=160$ и $L=180$.

Увеличим $N$ до $200$.
```{r}
N <- 200
Ls <- c(100, 160, 180)
model$N <- N
A <- 0.8
signal <- signal.one.channel(model$N, omega, A)
varphi <- 0.9
model$varphi <- varphi
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_noise_phi.9_1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, 0)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_noise_phi.9_1[[idx]] <- result
}

stopCluster(cluster)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_signal_phi.9_1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, signal)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_signal_phi.9_1[[idx]] <- result
}

stopCluster(cluster)
```

```{r}
alphaI_phi.9_1 <- lapply(p.values_noise_phi.9_1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
beta_phi.9_1 <- lapply(p.values_signal_phi.9_1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "Type I error", xlab = 'significance level', ylab = 'type I error')
for (i in seq_along(Ls))
  lines(alphas, alphaI_phi.9_1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "ROC curve", xlab = 'type I error', ylab = 'power')
for (i in seq_along(Ls))
  lines(alphaI_phi.9_1[[i]], beta_phi.9_1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Как видим, с увеличением $N$ радикальность стала больше, и $L=160$ радикальнее $L=180$. Различие остается с увеличением длины ряда.

Является ли $L=0.9N$ оптимальным для, например $\varphi=0.7$? Посмотрим, какой из критериев наиболее мощный при $L\in[90, 98]$.
```{r}
N <- 100
Ls <- c(90, 92, 94, 95, 96, 98)
model$N <- N
A <- 1
signal <- signal.one.channel(model$N, omega, A)
varphi <- 0.7
model$varphi <- varphi
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_noise_phi.7_1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, 0)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_noise_phi.7_1[[idx]] <- result
}

stopCluster(cluster)
```

```{r, include=FALSE}
cores <- detectCores()
cluster <- makeCluster(cores - 1)
registerDoSNOW(cluster)
registerDoRNG(seed = 1, once = FALSE)

p.values_signal_phi.7_1 <- list()
for (idx in seq_along(Ls)) {
  result <- foreach (
    i = 1:M,
    .combine = 'c',
    .export = c('Norm', 'rowQuantiles'),
    .packages = "Rssa",
    .options.snow = opts
  ) %dopar% {
    f <- one.channel.ts(model, signal)
    res <-
      MonteCarloSSA(
        f = f,
        L = Ls[idx],
        model = model,
        basis = "ev",
        kind = "ev",
        D = D,
        G = G,
        level.conf = NULL
      )
    res$p.value
  }
  p.values_signal_phi.7_1[[idx]] <- result
}

stopCluster(cluster)
```

```{r}
alphaI_phi.7_1 <- lapply(p.values_noise_phi.7_1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
beta_phi.7_1 <- lapply(p.values_signal_phi.7_1, function(pvals) sapply(alphas, function(a) sum(pvals < a) / M))
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "Type I error", xlab = 'significance level', ylab = 'type I error')
for (i in seq_along(Ls))
  lines(alphas, alphaI_phi.7_1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```

```{r}
plot(c(0,1),c(0,1), type="l", col = "blue", lty = 2, main = "ROC curve", xlab = 'type I error', ylab = 'power')
for (i in seq_along(Ls))
  lines(alphaI_phi.7_1[[i]], beta_phi.7_1[[i]], lwd = lwds[i], col = clrs[i])
legend(x = "bottomright", as.character(Ls), col = clrs, lty = 1, lwd = lwds)
```
Из всех представленных $L$ наиболее оптимальным является $L=96$.